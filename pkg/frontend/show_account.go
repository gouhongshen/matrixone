// Copyright 2021 Matrix Origin
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package frontend

import (
	"context"
	"fmt"
	"github.com/matrixorigin/matrixone/pkg/logutil"
	"math"
	"strings"
	//"time"

	//"github.com/matrixorigin/matrixone/pkg/logutil"
	"github.com/matrixorigin/matrixone/pkg/catalog"
	"github.com/matrixorigin/matrixone/pkg/common/moerr"
	"github.com/matrixorigin/matrixone/pkg/common/mpool"
	"github.com/matrixorigin/matrixone/pkg/container/batch"
	"github.com/matrixorigin/matrixone/pkg/container/vector"
	"github.com/matrixorigin/matrixone/pkg/defines"
	"github.com/matrixorigin/matrixone/pkg/fileservice"
	"github.com/matrixorigin/matrixone/pkg/pb/api"
	//"github.com/matrixorigin/matrixone/pkg/pb/plan"
	"github.com/matrixorigin/matrixone/pkg/sql/parsers/tree"
	"github.com/matrixorigin/matrixone/pkg/sql/plan/function/ctl"
	//v2 "github.com/matrixorigin/matrixone/pkg/util/metric/v2"
	"github.com/matrixorigin/matrixone/pkg/vm/engine/tae/db"
	"github.com/matrixorigin/matrixone/pkg/vm/engine/tae/logtail"
	"github.com/matrixorigin/matrixone/pkg/vm/process"
)

const (
	getSpecialTablesInfoFormat = "" +
		"select " +
		"	cast (count(distinct rel_id) as bigint) " +
		"from mo_catalog.mo_tables " +
		"where" +
		"	relkind in ('v','e','r','cluster')" +
		"	and reldatabase = 'mo_catalog'" +
		"	and account_id = %d;"

	getAccountInfoFormatV2 = "" +
		"SELECT" +
		"	cast(ma.account_id as bigint) as account_id," +
		"	ma.account_name," +
		"	ma.admin_name," +
		"	ma.created_time," +
		"	ma.status," +
		"	ma.suspended_time," +
		"	COUNT(DISTINCT md.dat_id) as db_count," +
		"	COUNT(DISTINCT mt.rel_id) as tbl_count," +
		"	cast(0 as double) as size," +
		"	ma.comments " +
		"FROM" +
		"	mo_catalog.mo_account AS ma " +
		"LEFT JOIN" +
		"	mo_catalog.mo_tables AS mt" +
		"	ON ma.account_id = mt.account_id AND mt.relkind IN ('v','r','e','cluster') " +
		"LEFT JOIN" +
		"	mo_catalog.mo_database AS md" +
		"	ON ma.account_id = md.account_id AND md.dat_type != 'subscription' " +
		"%s " + // where clause
		"GROUP BY" +
		"	ma.account_id, ma.account_name, ma.admin_name, ma.created_time, ma.status, ma.suspended_time, ma.comments " +
		"ORDER BY" +
		"	ma.account_name;"
	//"SELECT " +
	//"	cast(ma.account_id as bigint) as account_id," +
	//"	ma.account_name, " +
	//"	ma.admin_name, " +
	//"	ma.created_time, " +
	//"	ma.status, " +
	//"	ma.suspended_time," +
	//"	COUNT(DISTINCT md.dat_id) as db_count," +
	//"	COUNT(DISTINCT mt.rel_id) as tbl_count, " +
	//"	cast(0 as double) as size," +
	//"	ma.comments " +
	//"FROM mo_catalog.mo_account AS ma " +
	//"LEFT JOIN mo_catalog.mo_tables AS mt ON ma.account_id = mt.account_id " +
	//"LEFT JOIN mo_catalog.mo_database AS md ON ma.account_id = md.account_id " +
	//"Where md.dat_type != 'subscription' and mt.relkind in ('v','r','e','cluster') " +
	//"%s " + // like clause
	//"%s " + // account id clause
	//"GROUP BY ma.account_id, ma.account_name, ma.admin_name, ma.created_time, ma.status, ma.suspended_time, ma.comments " +
	//"ORDER BY ma.account_name;"
)

const (
	// column index in the result set generated by
	// the sql getAllAccountInfoFormat, getAccountInfoFormat
	idxOfAccountId = iota
	idxOfAccountName
	idxOfAdminName
	idxOfCreatedTime
	idxOfStatus
	idxOfSuspendedTime
	idxOfDbCount
	idxOfTableCount
	idxOfSize
	idxOfComment

	totalColumnCnt = 9
)

var cnUsageCache = logtail.NewStorageUsageCache(
	logtail.WithLazyThreshold(5))

func getSqlForAccountInfo(like *tree.ComparisonExpr, accId int64) string {
	var likePattern = ""
	if like != nil {
		likePattern = strings.TrimSpace(like.Right.String())
	}

	whereClause := ""

	if len(likePattern) != 0 {
		whereClause += "where "
		whereClause += fmt.Sprintf("account_name like '%s' ", likePattern)
	}

	if accId != -1 {
		if whereClause != "" {
			whereClause += "and "
		}
		whereClause += fmt.Sprintf("ma.account_id = '%d'", accId)
	}

	return fmt.Sprintf(getAccountInfoFormatV2, whereClause)
}

func requestStorageUsage(ctx context.Context, ses *Session, accIds [][]int64) (resp any, tried bool, err error) {
	whichTN := func(string) ([]uint64, error) { return nil, nil }
	payload := func(tnShardID uint64, parameter string, proc *process.Process) ([]byte, error) {
		req := db.StorageUsageReq{}
		for x := range accIds {
			req.AccIds = append(req.AccIds, accIds[x]...)
		}

		return req.Marshal()
	}

	responseUnmarshaler := func(payload []byte) (any, error) {
		usage := &db.StorageUsageResp{}
		if err := usage.Unmarshal(payload); err != nil {
			return nil, err
		}
		return usage, nil
	}

	txnOperator := ses.txnHandler.GetTxn()

	// create a new proc for `handler`
	proc := process.New(ctx, ses.proc.GetMPool(),
		ses.proc.TxnClient, txnOperator,
		ses.proc.FileService, ses.proc.LockService,
		ses.proc.QueryClient, ses.proc.Hakeeper,
		ses.proc.UdfService, ses.proc.Aicm,
	)

	handler := ctl.GetTNHandlerFunc(api.OpCode_OpStorageUsage, whichTN, payload, responseUnmarshaler)
	result, err := handler(proc, "DN", "", ctl.MoCtlTNCmdSender)
	if moerr.IsMoErrCode(err, moerr.ErrNotSupported) {
		// try the previous RPC method
		payload_V0 := func(tnShardID uint64, parameter string, proc *process.Process) ([]byte, error) { return nil, nil }
		responseUnmarshaler_V0 := func(payload []byte) (interface{}, error) {
			usage := &db.StorageUsageResp_V0{}
			if err := usage.Unmarshal(payload); err != nil {
				return nil, err
			}
			return usage, nil
		}

		tried = true
		CmdMethod_StorageUsage := api.OpCode(14)
		handler = ctl.GetTNHandlerFunc(CmdMethod_StorageUsage, whichTN, payload_V0, responseUnmarshaler_V0)
		result, err = handler(proc, "DN", "", ctl.MoCtlTNCmdSender)

		if moerr.IsMoErrCode(err, moerr.ErrNotSupported) {
			return nil, tried, moerr.NewNotSupportedNoCtx("current tn version not supported `show accounts`")
		}
	}

	if err != nil {
		return nil, tried, err
	}

	return result.Data.([]any)[0], tried, nil
}

func handleStorageUsageResponse_V0(ctx context.Context, fs fileservice.FileService,
	usage *db.StorageUsageResp_V0) (map[int64]uint64, error) {
	result := make(map[int64]uint64, 0)
	for idx := range usage.CkpEntries {
		version := usage.CkpEntries[idx].Version
		location := usage.CkpEntries[idx].Location

		// storage usage was introduced after `CheckpointVersion9`
		if version < logtail.CheckpointVersion9 {
			// exist old version checkpoint which hasn't storage usage data in it,
			// to avoid inaccurate info leading misunderstand, we chose to return empty result
			logutil.Info("[storage usage]: found older ckp when handle storage usage response")
			return map[int64]uint64{}, nil
		}

		ckpData, err := logtail.LoadSpecifiedCkpBatch(ctx, location, version, logtail.StorageUsageInsIDX, fs)
		if err != nil {
			return nil, err
		}

		storageUsageBat := ckpData.GetBatches()[logtail.StorageUsageInsIDX]
		accIDVec := vector.MustFixedCol[uint64](
			storageUsageBat.GetVectorByName(catalog.SystemColAttr_AccID).GetDownstreamVector(),
		)
		sizeVec := vector.MustFixedCol[uint64](
			storageUsageBat.GetVectorByName(logtail.CheckpointMetaAttr_ObjectSize).GetDownstreamVector(),
		)

		size := uint64(0)
		length := len(accIDVec)
		for i := 0; i < length; i++ {
			result[int64(accIDVec[i])] += sizeVec[i]
			size += sizeVec[i]
		}

		ckpData.Close()
	}

	// [account_id, db_id, table_id, obj_id, table_total_size]
	for _, info := range usage.BlockEntries {
		result[int64(info.Info[0])] += info.Info[3]
	}

	return result, nil
}

func handleStorageUsageResponse(
	ctx context.Context,
	usage *db.StorageUsageResp,
) (map[int64]uint64, error) {
	result := make(map[int64]uint64, 0)

	for x := range usage.AccIds {
		result[usage.AccIds[x]] += usage.Sizes[x]
	}

	return result, nil
}

func checkStorageUsageCache(accIds [][]int64) (result map[int64]uint64, succeed bool) {
	cnUsageCache.Lock()
	defer cnUsageCache.Unlock()

	if cnUsageCache.IsExpired() {
		return nil, false
	}

	result = make(map[int64]uint64)
	for x := range accIds {
		for y := range accIds[x] {
			size, exist := cnUsageCache.GatherAccountSize(uint64(accIds[x][y]))
			if !exist {
				// one missed, update all
				return nil, false
			}

			result[accIds[x][y]] = size
		}
	}

	return result, true
}

func updateStorageUsageCache(accIds []int64, sizes []uint64) {

	if len(accIds) == 0 {
		return
	}

	cnUsageCache.Lock()
	defer cnUsageCache.Unlock()

	// step 1: delete stale accounts
	cnUsageCache.ClearForUpdate()

	// step 2: update
	for x := range accIds {
		usage := logtail.UsageData{AccId: uint64(accIds[x]), Size: sizes[x]}
		if old, exist := cnUsageCache.Get(usage); exist {
			usage.Size += old.Size
		}

		cnUsageCache.SetOrReplace(usage)
	}
}

// getAccountStorageUsage calculates the storage usage of all accounts
// by handling checkpoint
func getAccountsStorageUsage(ctx context.Context, ses *Session, accIds [][]int64) (map[int64]uint64, error) {
	if len(accIds) == 0 {
		return nil, nil
	}

	// step 1: check cache
	if usage, succeed := checkStorageUsageCache(accIds); succeed {
		return usage, nil
	}

	// step 2: query to tn
	response, tried, err := requestStorageUsage(ctx, ses, accIds)
	if err != nil {
		return nil, err
	}

	if tried {
		usage, ok := response.(*db.StorageUsageResp_V0)
		if !ok {
			return nil, moerr.NewInternalErrorNoCtx("storage usage response decode failed, retry later")
		}

		fs, err := fileservice.Get[fileservice.FileService](getGlobalPu().FileService, defines.SharedFileServiceName)
		if err != nil {
			return nil, err
		}

		// step 3: handling these pulled data
		return handleStorageUsageResponse_V0(ctx, fs, usage)

	} else {
		usage, ok := response.(*db.StorageUsageResp)
		if !ok || usage.Magic != logtail.StorageUsageMagic {
			return nil, moerr.NewInternalErrorNoCtx("storage usage response decode failed, retry later")
		}

		updateStorageUsageCache(usage.AccIds, usage.Sizes)

		// step 3: handling these pulled data
		return handleStorageUsageResponse(ctx, usage)
	}
}

func updateStorageSize(ori *batch.Batch, size uint64, mp *mpool.MPool) {
	vector.SetFixedAt(ori.Vecs[idxOfSize], 0, math.Round(float64(size)/1048576.0*1e6)/1e6)
}

func updateTableCount(ori *batch.Batch, specialTableCnt int64, mp *mpool.MPool) {
	old := vector.GetFixedAt[int64](ori.Vecs[idxOfTableCount], 0)
	vector.SetFixedAt[int64](ori.Vecs[idxOfTableCount], 0, old+specialTableCnt)
}

func doShowAccounts(ctx context.Context, ses *Session, sa *tree.ShowAccounts) (err error) {
	var sql string
	var accIds [][]int64
	var accInfosBatches []*batch.Batch
	var eachAccountInfo []*batch.Batch
	var tempBatch *batch.Batch
	//var MoAccountColumns, EachAccountColumns *plan.ResultColDef
	//var outputBatches []*batch.Batch
	var specialTableCnt int64

	mp := ses.GetMemPool()

	defer func() {
		for _, b := range accInfosBatches {
			if b == nil {
				continue
			}
			b.Clean(mp)
		}

		for _, b := range eachAccountInfo {
			if b == nil {
				continue
			}
			b.Clean(mp)
		}
		if tempBatch != nil {
			tempBatch.Clean(mp)
		}
	}()

	bh := ses.GetRawBatchBackgroundExec(ctx)
	defer bh.Close()

	account := ses.GetTenantInfo()

	err = bh.Exec(ctx, "begin;")
	defer func() {
		err = finishTxn(ctx, bh, err)
	}()

	if err != nil {
		return err
	}

	if account.IsSysTenant() {
		sql = getSqlForAccountInfo(sa.Like, -1)
		if accInfosBatches, accIds, err = getAccountInfo(ctx, bh, sql); err != nil {
			return err
		}

		// normal account
	} else {
		if sa.Like != nil {
			return moerr.NewInternalError(ctx, "only sys account can use LIKE clause")
		}
		// switch to the sys account to get account info
		newCtx := defines.AttachAccountId(ctx, uint32(sysAccountID))
		sql = getSqlForAccountInfo(nil, int64(account.GetTenantID()))
		if accInfosBatches, accIds, err = getAccountInfo(newCtx, bh, sql); err != nil {
			return err
		}

		if len(accInfosBatches) != 1 {
			return moerr.NewInternalError(ctx, "no such account %v", account.GetTenantID())
		}
	}

	backSes := bh.(*backExec)
	resultSet := backSes.backSes.allResultSet[0]
	columnDef := backSes.backSes.rs
	bh.ClearExecResultSet()

	for _, id := range accIds {
		if id[0] == sysAccountID {
			continue
		}
		if specialTableCnt, err = getSpecialTableInfo(ctx, bh, id[0]); err != nil {
			return err
		}
		break
	}

	usage, err := getAccountsStorageUsage(ctx, ses, accIds)
	if err != nil {
		return err
	}

	for idx := range accIds {
		updateStorageSize(accInfosBatches[idx], usage[accIds[idx][0]], mp)
		if accIds[idx][0] != sysAccountID {
			updateTableCount(accInfosBatches[idx], specialTableCnt, mp)
		}
	}

	outputRS := &MysqlResultSet{}
	if err = initOutputRs(outputRS, resultSet, ctx); err != nil {
		return err
	}

	oq := newFakeOutputQueue(outputRS)
	for _, b := range accInfosBatches {
		if err = fillResultSet(ctx, oq, b, ses); err != nil {
			return err
		}
	}

	ses.SetMysqlResultSet(outputRS)

	ses.rs = columnDef
	if openSaveQueryResult(ctx, ses) {
		err = saveResult(ctx, ses, accInfosBatches)
	}

	return err

}

func saveResult(ctx context.Context, ses *Session, outputBatch []*batch.Batch) error {
	for _, b := range outputBatch {
		if err := saveQueryResult(ctx, ses, b); err != nil {
			return err
		}
	}
	if err := saveQueryResultMeta(ctx, ses); err != nil {
		return err
	}
	return nil
}

func initOutputRs(dest *MysqlResultSet, src *MysqlResultSet, ctx context.Context) error {
	for idx := idxOfAccountId; idx <= totalColumnCnt; idx++ {
		o, err := src.GetColumn(ctx, uint64(idx))
		if err != nil {
			return err
		}
		dest.AddColumn(o)
	}
	return nil
}

// getAccountInfo gets account info from mo_account under sys account
func getAccountInfo(ctx context.Context,
	bh BackgroundExec,
	sql string) ([]*batch.Batch, [][]int64, error) {
	var err error
	var accountIds [][]int64
	var rsOfMoAccount []*batch.Batch

	bh.ClearExecResultBatches()
	err = bh.Exec(ctx, sql)
	if err != nil {
		return nil, nil, err
	}

	rsOfMoAccount = bh.GetExecResultBatches()
	if len(rsOfMoAccount) == 0 {
		return nil, nil, moerr.NewInternalError(ctx, "no account info")
	}

	batchCount := len(rsOfMoAccount)
	accountIds = make([][]int64, batchCount)
	for i := 0; i < batchCount; i++ {
		vecLen := rsOfMoAccount[i].Vecs[0].Length()
		for row := 0; row < vecLen; row++ {
			accountIds[i] = append(accountIds[i], vector.GetFixedAt[int64](rsOfMoAccount[i].Vecs[0], row))
		}
	}

	return rsOfMoAccount, accountIds, err
}

func getSpecialTableInfo(ctx context.Context, bh BackgroundExec, accId int64) (tblCnt int64, err error) {
	sql := fmt.Sprintf(getSpecialTablesInfoFormat, sysAccountID)
	newCtx := defines.AttachAccountId(ctx, uint32(accId))

	bh.ClearExecResultBatches()
	err = bh.Exec(newCtx, sql)
	if err != nil {
		return 0, err
	}

	ret := bh.GetExecResultBatches()
	if len(ret) == 0 {
		return 0, moerr.NewInternalError(ctx, "no special table info")
	}

	if len(ret) != 1 || len(ret[0].Vecs) != 1 {
		return 0, moerr.NewInternalError(ctx, "special table ret count should be one")
	}

	tblCnt = vector.MustFixedCol[int64](ret[0].Vecs[0])[0]
	return tblCnt, nil
}
